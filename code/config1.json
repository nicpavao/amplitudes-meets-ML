{
    "model_params": {
      "model": "MLP",
      "input_dim": 5,
      "hidden_dim": 512,
      "output_dim": 1
    },
    "training_params": {
      "learning_rate": 1e-3,
      "batch_size": 32,
      "num_epochs": 100,
      "optimizer": "Adam"
    },
    "log_params": {
      "experiment_name": "experiment_001",
      "notes": "Baseline experiment with MLP"
    }
  }